---
title: "Forecasting the US Presidential Election: A Poll-of-Polls Approach Using Linear Models By Using Data of Pollsters From Five Thirty Eight In 2024"
author: 
  - Ziqi Zhu
  - Yuanchen Miao
  - Claire Chang
thanks: "Code and data are available at: https://github.com/zzq20010617/2024_USelection_prediction"
date: today
date-format: long
abstract: "This paper presents a multiple linear regression model for forecasting the outcome of the 2024 U.S. Presidential Election. Using nationwide polling data, we predict the percentage of support for U.S. presidential candidates based on key factors such as sample size, pollster quality, and timing. Our model aggregates these predictions to simulate potential election outcomes. The results reveal how specific poll attributes affect the accuracy of forecasts, offering valuable insights for predicting the likelihood of various electoral scenarios."
number-sections: true
bibliography: references.bib
format:
  pdf:
    toc: true
    number-sections: true
    colorlinks: true
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(rstanarm)
library(splines)
```

```{r}
#| include: false
#| warning: false
#| message: false

cleaned_data <- read_csv(here::here("data/02-analysis_data/cleaned_data.csv"))
nationwide_data <- cleaned_data %>%  filter(state == "National")

# only two entries for Conservative Party
unique_parties <- unique(nationwide_data$party)

# drop columns that have NA in numeric_grade or pollscore, and 2 entries for CON party
nationwide_data <- nationwide_data %>%
  drop_na(numeric_grade, pollscore) %>%
  filter(party != "CON") %>%
  mutate(days_since_start = as.numeric(end_date - min(end_date)))

unique_parties <- unique(nationwide_data$party)
nationwide_data$party <- as.factor(nationwide_data$party)

nationwide_data <- nationwide_data %>% mutate(
  num_party = round((pct / 100) * sample_size, 0)
)
# filter nationwide_data by parties
dem_data <- nationwide_data %>%
  filter(party == "DEM")
dem_data <- na.omit(dem_data)

dem_data <- dem_data |>
  mutate(
    pollster = factor(pollster)
  )

rep_data <- nationwide_data %>%
  filter(party == "REP")
rep_data <- na.omit(rep_data)

rep_data <- rep_data |>
  mutate(
    pollster = factor(pollster)
  )
```

# Introduction

This paper examines the development of a multiple linear regression (MLR) model to predict the percentage of support (pct) for U.S. presidential candidates based on polling data. The data includes a range of predictors, such as sample size, pollster quality factors, and time-related factors. The focus of the analysis is on nationwide polling data, aggregated from different pollsters, to create a robust model for forecasting election outcomes. The goal is to provide a clearer understanding of how various poll attributes influence polling results and to derive insights that can predict election outcomes.

The primary estimand in this study is the expected percentage of support (pct) for a U.S. presidential candidate, given polling data and relevant predictor variables like rating of the pollster and sample size of the poll.

Our Results shows that

This analysis is useful in understanding how various polling factors contribute to predicting election results. By modeling the relationship between polling result and factors, the study enhances the ability to forecast election outcomes based on public opinion data. This model provides a practical tool for researchers, political strategists, and analysts to assess the reliability of polling data and its implications for elections.


# Data {#sec-data}

## Overview

Our data is download from [Five Thirty Eight](https://projects.fivethirtyeight.com/polls)[@polls], the website gathered survey data from different pollsters of 2024 US president election, We use the statistical programming **language R** [@citeR], and packages **lubridate**[@lubridate], **dplyr**[@dplyr], **tidyverse**[@tidyverse], **model summary**[@models] to process the data. Also, we use **tibble** [@tibble] to create the table for simulate table and save it as csv files. Graphs are created by using ggplot2 in from package **tidyverse**[@tidyverse]Following **Telling stories with data**[@telling_stories_with_data], we consider using multiple linear model to predict and forecasting the result of US president election in 2024. We are creating different graphs and models for the candidates from different parties in general state and combine all models and graphs together to create a new scatter plot to predict and forecasting the US president election in 2024.

## Measurement
	
The dataset is about public opinions about U.S. presidential candidates, which are captured through polling.

## Outcome variables {#sec-octvar}

Our primary outcome variable is **support percentage (pct)**, which represents the percentage of respondents who support each candidate. This variable is modeled as the response variable in the MLR analyse.

```{r}
#| label: fig-bills
#| fig-cap: Bills of penguins
#| echo: false

# ggplot(penguins, aes(x = island, fill = species)) +
#   geom_bar(alpha = 0.8) +
#   scale_fill_manual(values = c("darkorange","purple","cyan4"),
#                     guide = "none") +
#   theme_minimal() +
#   facet_wrap(~species, ncol = 1) +
#   coord_flip()
```

Talk more about it.

And also planes (@fig-planes). (You can change the height and width, but don't worry about doing that until you have finished every other aspect of the paper - Quarto will try to make it look nice and the defaults usually work well once you have enough text.)

```{r}
#| label: fig-planes
#| fig-cap: Relationship between wing length and width
#| echo: false
#| warning: false
#| message: false

# analysis_data <- read_csv(here::here("data/02-analysis_data/analysis_data.csv"))
# 
# analysis_data |> 
#   ggplot(aes(x = width, y = length)) +
#   geom_point(alpha = 0.8) +
#   theme_minimal() +
#   labs(x = "Wing width (mm)",
#        y = "Wing length (mm)")
```

Talk way more about it. 

## Predictor variables {#sec-prevar}

### Sample Size

Sample size is an important predictor because it influences the reliability of a poll. Larger sample sizes tend to reduce sampling error, providing more accurate reflections of voter sentiment. In our MLR model, the sample size is log-transformed to account for diminishing returns—larger polls do not necessarily offer proportionally better accuracy.

### Poll Score

The poll score is a measure of the error and bias we can attribute to a pollster, negative number is better.

### Numeric Grade

This variable is an aggregate score of the poll based on a numeric scale. It serves as an indicator of the pollster's historical performance and the methodology used. 3 is the maximum and some pollsters have no rating.

### Transparency Score

Transparency score measures how openly a pollster reports their methodology and results. A higher transparency score suggests that the pollster has disclosed key details about how the poll was conducted, improving trust in the poll results.

### Days Since Start

This variable represents the number of days since the beginning of the election polling period. It helps capture the dynamic nature of voter preferences over time, accounting for shifts in public opinion as the election date nears.


# Models

The goal of our modelling strategy is try to capture the. Firstly,...
In the following section we briefly describe the models we used to investigate. Background details and diagnostics are included in [Appendix -@sec-model-details].

## MLR Model set-up
We first filtered our data by different parties, as the single linear model but include other 3 parties(GRE, IND, and LIB, Conservative only has two entries in cleaned nationwide data and has 0 pct so its been removed), and fit linear model for each of them. The formula for Multiple linear regression is as follow
\begin{align}
\text{pct}_i &= \beta_0 + \beta_1 \log(\text{sample\_size}_i) + \beta_2 \, \text{pollscore}_i + \beta_3 \, \text{numeric\_grade}_i \\
&+ \beta_4 \, \text{transparency\_score}_i + \beta_5 \, \text{days\_since\_start}_i + \epsilon_i
\end{align}

Response Variable is pct. Predictors are log(sample_size), pollscore, numeric_grade, transparency_score, and days_since_start, detail can be found in [@sec-octvar], and [@sec-prevar]

### Result

Our results for the MLR model are summarized in @tbl-mlrmodelresults.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

MLR_models <-
  readRDS(file = here::here("models/MLRmodels.rds"))
```

```{r}
#| echo: false
#| eval: true
#| label: tbl-mlrmodelresults
#| tbl-cap: "Explanatory models of pct based on pollscore, sample size, and time"
#| warning: false

modelsummary::modelsummary(
  MLR_models,
  fmt = 2
)
```
We first check the residual vs. fitted plot as shown in [Appendix @sec-model-details], and see no obvious violation of assumptions. According to the summary, DEM and REP models are based on the largest number of observations (both 1235). Smaller parties have fewer observations, which may lead to less robust models. The $r^2$ shows that the model explain the highest amount of variance on Democratic Party than others with value 0.357, and other parties less than 0.2. Based on the summary of models for DEM and REP [@sec-model-sigcheck], we are not sure if those predictor that measure quality of polls are significant or not, so we keep them for now in Bayesian model. Prediction of MLR models is shown in [@fig-mlrpredict], which we can see blue line which is Democratic party has a steeper slope and start to take the lead between day 100 and day 200.

```{r}
#| echo: false
#| label: fig-mlrpredict
#| fig-cap: "Prediction with MLR models for DEM and REP party"
#| warning: false

# Augment the datasets with predictions
dem_data <- dem_data |>
  mutate(fitted_pct_dem = predict(MLR_models[['DEM']]))
rep_data <- rep_data |>
  mutate(fitted_pct_rep = predict(MLR_models[['REP']]))

# Combine both datasets into one
combined_data <- bind_rows(dem_data, rep_data)

# Plot with colors based on the party
ggplot(combined_data, aes(x = days_since_start)) +
  geom_line(aes(y = fitted_pct_dem, color = "DEM")) +
  geom_line(aes(y = fitted_pct_rep, color = "REP")) +
  scale_color_manual(values = c("DEM" = "blue", "REP" = "red"), 
                     name = "Party",
                     labels = c("DEM (Blue)", "REP (Red)")) +
  theme_classic() +
  labs(y = "Percent", x = "Days") +
  theme(legend.position = "top")
```

## Bayesian Model set-up
The Bayesian model is build from the MLR models from above section. With the inspiration from the example R code, we introduce the random effects for Pollsters, and we use a logistic link to predict the probability of support, modeling count data which is in binomial distribution. We choose to use a default prior and enable autoscale, the formula is shown below

\begin{align} 
\log \left( \frac{p_i}{1 - p_i} \right) &= \beta_0 + \beta_1 \log(\text{sample\_size}_i) + \beta_2 \, \text{pollscore}_i + \beta_3 \, \text{numeric\_grade}_i \\
&+ \beta_4 \, \text{transparency\_score}_i + \beta_5 \, \text{days\_since\_start}_i + \alpha_j
\alpha_j &\sim \text{Normal}(0, \sigma_{\text{pollster}}) \\
\beta_0 &\sim \text{Normal}(0, 2.5) \\
\beta_1 &\sim \text{Normal}(0, 2.5) \\
\beta_2 &\sim \text{Normal}(0, 2.5) \\
\beta_3 &\sim \text{Normal}(0, 2.5) \\
\beta_4 &\sim \text{Normal}(0, 2.5) \\
\beta_5 &\sim \text{Normal}(0, 2.5) \\
\sigma_{\text{pollster}} &\sim \text{Exponential}(1)
\end{align}

$y_i$ represent the number of individuals in the sample that support the Democratic party (this corresponds to num_party).
The response is modeled as binomial: $y_i \sim \text{Binomial}(\text{sample\_size}_i, p_i)$, where $p_i$ is the probability that an individual in poll $i$ supports the Democratic party, and $\text{sample\_size}_i$ is the total number of individuals surveyed in poll $i$.

### Result
Summary of Bayesian model is hsown in [@tbl-baymodelresults], and the ppcheck is in appendix [@fig-ppcheck]. 
```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

Bay_model <-
  readRDS(file = here::here("models/bayesian_model_dem.rds"))
```

```{r}
#| echo: false
#| eval: true
#| label: tbl-baymodelresults
#| tbl-cap: ""
#| warning: false

modelsummary::modelsummary(
  Bay_model,
  fmt = 2
)
```

# Prediction

To get a prediction by the Vayesian model we have, we first spline fit the model, and then create a data frame and generate posterior predictions by the new data frame.
## Spline Fit for Bayesian model set-up

We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use priors $\text{Normal}(0, 5)$ to allow for more flexibility of predictors effects with “autoscale = TRUE”. Then we crate a data frame like [@tbl-newdata], we set the quality scale of predict data to the best to perform a poll that has high quality. the result is shown as [@sec-splresult]
```{r}
#| echo: false
#| warning: false
#| message: false
#| label: tbl-newdata

# Create new data for prediction
new_data <- data.frame(
  pollscore = -1.5,
  sample_size = 1200,
  numeric_grade = 3,
  transparency_score=10,
  days_since_start = seq(
    min(dem_data$days_since_start),
    max(dem_data$days_since_start),
    length.out = 100
  ),
  pollster = factor("TIPP", levels = levels(dem_data$pollster))
)

head(new_data)
```

## Result {#sec-splresult}
```{r}
#| echo: false
#| warning: false
#| message: false

spline_dem <-
  readRDS(file = here::here("models/spline_dem.rds"))
spline_rep <-
  readRDS(file = here::here("models/spline_rep.rds"))
```

```{r}
#| echo: false
#| label: fig-splpredict
#| fig-cap: "Poll Percentage over Time with Spline Fit for DEM and REP party"
#| warning: false


posterior_preds_dem <- posterior_predict(spline_dem, newdata = new_data)
posterior_preds_rep <- posterior_predict(spline_rep, newdata = new_data)

combined_data <- bind_rows(dem_data, rep_data)

# Summarize predictions
pred_summary_dem <- new_data |>
  mutate(
    pred_mean_dem = colMeans(posterior_preds_dem),
    pred_lower_dem = apply(posterior_preds_dem, 2, quantile, probs = 0.025),
    pred_upper_dem = apply(posterior_preds_dem, 2, quantile, probs = 0.975),
    party = "DEM"
  )

# Summarize predictions for REP
pred_summary_rep <- new_data |>
  mutate(
    pred_mean_rep = colMeans(posterior_preds_rep),
    pred_lower_rep = apply(posterior_preds_rep, 2, quantile, probs = 0.025),
    pred_upper_rep = apply(posterior_preds_rep, 2, quantile, probs = 0.975),
    party = "REP"
  )

# Combine both summaries into a single dataframe
pred_summary <- bind_rows(pred_summary_dem, pred_summary_rep)

# Plot the spline fit
ggplot(combined_data, aes(x = days_since_start, y = pct, color = pollster)) +
  # DEM predictions
  geom_line(
    data = pred_summary %>% filter(party == "DEM"),
    aes(x = days_since_start, y = pred_mean_dem, color = "DEM"),
    inherit.aes = FALSE
  ) +
  geom_ribbon(
    data = pred_summary %>% filter(party == "DEM"),
    aes(x = days_since_start, ymin = pred_lower_dem, ymax = pred_upper_dem, fill = "DEM"),
    alpha = 0.2,
    inherit.aes = FALSE
  ) +
  # REP predictions
  geom_line(
    data = pred_summary %>% filter(party == "REP"),
    aes(x = days_since_start, y = pred_mean_rep, color = "REP"),  # Move color inside aes()
    inherit.aes = FALSE
  ) +
  geom_ribbon(
    data = pred_summary %>% filter(party == "REP"),
    aes(x = days_since_start, ymin = pred_lower_rep, ymax = pred_upper_rep, fill = "REP"),  # Move fill inside aes()
    alpha = 0.2,
    inherit.aes = FALSE
  ) +
  # Use scale_color_manual and scale_fill_manual for colors and fills
  scale_color_manual(values = c("DEM" = "blue", "REP" = "red"), 
                     name = "Party",
                     labels = c("DEM (Blue)", "REP (Red)")) +
  scale_fill_manual(values = c("DEM" = "blue", "REP" = "red"), 
                    name = "Party",
                    labels = c("DEM (Blue)", "REP (Red)")) +
  labs(
    x = "Days since 2024",
    y = "Percentage",
  ) +
  theme_minimal()
```
The prediction graph contains prediction of spline fit model for two parties, blue line represents the DEM party's predicted percentage of support, and the red line represents the REP party's predicted percentage of support over time (measured in days since the start of 2024). We can tell that the predict support of DEM party is taking the lead by aroud 2 percent until the last day of the dataset.

# Discussion

## Crossing point in the prediction  {#sec-first-point}

From the prediction of spline fit model [@fig-splpredict], There is a clear increase in the support for the DEM party starting around day 200, while the REP party's support remains more stable with only a slight increase over time.
The increase in support for the DEM party in the predictions could be attributed to Harris's rise as the Democratic candidate after Biden's exit from the race On July 21, 2024, which is about 230 days from start of 2024. 


## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {-}

## Idealized  Survey and Methodology


## Trafalgar group’s methodology overview and evaluation 

The Trafalgar Group conducts polls ranging from major political campaigns to marketing surveys. The organization's 0.7 pollster rating indicates moderate accuracy and reliability compared to other pollsters. The population consists of all eligible voters in the U.S., while the sampling frame includes registered voters across states, segmented by demographics like age, gender, party affiliation, and ethnicity. Trafalgar Group typically samples likely voters, focusing on those most likely to participate in upcoming elections. Trafalgar Group recruits its sample using a mix of interactive voice response (IVR), live phone calls, text messages, online panels, and email surveys. Trafalgar Group employs stratified random sampling to ensure proportional representation of subgroups like political party, gender, and region. This method improves accuracy by reflecting the electorate's demographic and political makeup but may risk over-stratification, giving smaller voter groups disproportionate influence and potentially skewing results. Trafalgar Group handles non-response by using weighting to adjust the sample, ensuring respondent demographics match population parameters. This method reduces bias by accounting for underrepresented groups, though heavy reliance on post-survey adjustments may introduce new biases, particularly when there are large discrepancies in response rates across demographics.



# Model details {#sec-model-details}
## Assumption check for MLR models
```{r}
#| echo: false
#| eval: true
#| warning: false
#| fig.cap: "Residuals vs Fitted for DEM Party"

plot(MLR_models[['DEM']], which = 1, main = "Residuals vs Fitted for DEM Party")
```

```{r}
#| echo: false
#| eval: true
#| warning: false
#| fig.cap: "Residuals vs Fitted for REP Party"

plot(MLR_models[['REP']], which = 1, main = "Residuals vs Fitted for REP Party")
```
## Significant check for MLR models {#sec-model-sigcheck}
see [@tbl-mlrmodelsum-dem], and [@tbl-mlrmodelsum-rep]
```{r}
#| echo: false
#| eval: true
#| label: tbl-mlrmodelsum-dem
#| tbl-cap: "Summary of DEM data fit by MLR model"
#| warning: false

summary(MLR_models[['DEM']])
```
```{r}
#| echo: false
#| eval: true
#| label: tbl-mlrmodelsum-rep
#| tbl-cap: "Summary of REP data fit by MLR model"
#| warning: false

summary(MLR_models[['REP']])
```

\newpage
## Posterior predictive check {#sec-model-ppcheck}

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheck
#| fig-cap: "Posterior prediction check for Bayesian model"


pp_check(Bay_model)

```

## Diagnostics

<!-- @fig-stanareyouokay-1 is a trace plot. It shows... This suggests... -->

<!-- @fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests... -->

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

# plot(first_model, "trace")
# 
# plot(first_model, "rhat")
```





\newpage


# References


